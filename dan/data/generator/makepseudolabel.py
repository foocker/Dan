import numpy as np
import pandas as pd
import os
import shutil as sh
from os.path import join
import torch

datapath = "/vdata/dataset/global-wheat-detection"

# https://towardsdatascience.com/pseudo-labeling-to-deal-with-small-datasets-what-why-how-fd6f903213af
# https://medium.com/@nainaakash012/meta-pseudo-labels-6480acb1b68
# https://github.com/shubhamjn1/Pseudo-Labelling---A-Semi-supervised-learning-technique/blob/master/Pseudo-Labelling.ipynb
# https://github.com/anirudhshenoy/pseudo_labeling_small_datasets
# https://www.analyticsvidhya.com/blog/2017/09/pseudo-labelling-semi-supervised-learning-technique/
# https://www.kaggle.com/cdeotte/pseudo-labeling-qda-0-969


def convertTrainLabel():
    df = pd.read_csv(join(datapath, "train.csv"))
    bboxs = np.stack(
        df['bbox'].apply(lambda x: np.fromstring(x[1:-1], sep=',')))
    for i, column in enumerate(['x', 'y', 'w', 'h']):
        df[column] = bboxs[:, i]
    df.drop(columns=['bbox'], inplace=True)
    df['x_center'] = df['x'] + df['w'] / 2
    df['y_center'] = df['y'] + df['h'] / 2
    df['classes'] = 0
    df = df[[
        'image_id', 'x', 'y', 'w', 'h', 'x_center', 'y_center', 'classes'
    ]]

    index = list(set(df.image_id))

    source = 'train'
    if True:
        for fold in [0]:
            val_index = index[len(index) * fold // 5:len(index) * (fold + 1) //
                              5]
            for name, mini in df.groupby('image_id'):
                if name in val_index:
                    path2save = 'val2017/'
                else:
                    path2save = 'train2017/'
                if not os.path.exists(
                        './convertor/fold{}/labels/'.format(fold) + path2save):
                    os.makedirs('./convertor/fold{}/labels/'.format(fold) +
                                path2save)
                with open(
                        './convertor/fold{}/labels/'.format(fold) + path2save +
                        name + ".txt", 'w+') as f:
                    row = mini[['classes', 'x_center', 'y_center', 'w',
                                'h']].astype(float).values
                    row = row / 1024
                    row = row.astype(str)
                    for j in range(len(row)):
                        text = ' '.join(row[j])
                        f.write(text)
                        f.write("\n")
                if not os.path.exists('convertor/fold{}/images/{}'.format(
                        fold, path2save)):
                    os.makedirs('convertor/fold{}/images/{}'.format(
                        fold, path2save))
                sh.copy(
                    datapath + "\{}\{}.jpg".format(source, name),
                    'convertor/fold{}/images/{}/{}.jpg'.format(
                        fold, path2save, name))


# convertTrainLabel()

from ensemble_boxes import *


# https://github.com/ZFTurbo/Weighted-Boxes-Fusion

def run_wbf(boxes,
            scores,
            image_size=1023,
            iou_thr=0.5,
            skip_box_thr=0.7,
            weights=None):
    #boxes = [prediction[image_index]['boxes'].data.cpu().numpy()/(image_size-1) for prediction in predictions]
    #scores = [prediction[image_index]['scores'].data.cpu().numpy() for prediction in predictions]
    labels = [np.zeros(score.shape[0]) for score in scores]
    boxes = [box / (image_size) for box in boxes]
    boxes, scores, labels = weighted_boxes_fusion(boxes,
                                                  scores,
                                                  labels,
                                                  weights=None,
                                                  iou_thr=iou_thr,
                                                  skip_box_thr=skip_box_thr)
    #boxes, scores, labels = nms(boxes, scores, labels, weights=[1,1,1,1,1], iou_thr=0.5)
    boxes = boxes * (image_size)
    return boxes, scores, labels


def TTAImage(image, index):
    image1 = image.copy()
    if index == 0:
        rotated_image = cv2.rotate(image1, cv2.ROTATE_90_CLOCKWISE)
        return rotated_image
    elif index == 1:
        rotated_image2 = cv2.rotate(image1, cv2.ROTATE_90_CLOCKWISE)
        rotated_image2 = cv2.rotate(rotated_image2, cv2.ROTATE_90_CLOCKWISE)
        return rotated_image2
    elif index == 2:
        rotated_image3 = cv2.rotate(image1, cv2.ROTATE_90_CLOCKWISE)
        rotated_image3 = cv2.rotate(rotated_image3, cv2.ROTATE_90_CLOCKWISE)
        rotated_image3 = cv2.rotate(rotated_image3, cv2.ROTATE_90_CLOCKWISE)
        return rotated_image3
    elif index == 3:
        return image1


def rotBoxes90(boxes, im_w, im_h):
    ret_boxes = []
    for box in boxes:
        x1, y1, x2, y2 = box
        x1, y1, x2, y2 = x1 - im_w // 2, im_h // 2 - y1, x2 - im_w // 2, im_h // 2 - y2
        x1, y1, x2, y2 = y1, -x1, y2, -x2
        x1, y1, x2, y2 = int(x1 + im_w // 2), int(im_h // 2 - y1), int(x2 + im_w // 2), int(im_h // 2 -y2)
        x1a, y1a, x2a, y2a = min(x1, x2), min(y1, y2), max(x1, x2), max(y1, y2)
        ret_boxes.append([x1a, y1a, x2a, y2a])
    return np.array(ret_boxes)


def detect1Image(im0, imgsz, model, device, conf_thres, iou_thres):
    img = letterbox(im0, new_shape=imgsz)[0]
    # Convert
    img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, to 3x416x416
    img = np.ascontiguousarray(img)

    img = torch.from_numpy(img).to(device)
    img = img.float()  # uint8 to fp16/32
    img /= 255.0
    if img.ndimension() == 3:
        img = img.unsqueeze(0)

    # Inference
    pred = model(img, augment=False)[0]

    # Apply NMS
    pred = non_max_suppression(pred, conf_thres, iou_thres)

    boxes = []
    scores = []
    for i, det in enumerate(pred):  # detections per image
        # save_path = 'draw/' + image_id + '.jpg'
        if det is not None and len(det):
            # Rescale boxes from img_size to im0 size
            det[:, :4] = scale_coords(img.shape[2:], det[:, :4],
                                      im0.shape).round()

            # Write results
            for *xyxy, conf, cls in det:
                boxes.append(
                    [int(xyxy[0]),
                     int(xyxy[1]),
                     int(xyxy[2]),
                     int(xyxy[3])])
                scores.append(conf)

    return np.array(boxes), np.array(scores)


from utils.datasets import *
from utils.utils import *

yodatap = '/vdata/dataset/global-wheat-detection_yolo/'
yodatap_pseudo = '/vdata/dataset/global-wheat-detection_yolo/'


def makePseudolabel():
    source = join(datapath, "test")
    print(source)
    weights = 'weights/best.pt'
    imgsz = 1024
    conf_thres = 0.5
    iou_thres = 0.6
    is_TTA = True

    imagenames = os.listdir(source)

    device = torch.device(
        'cuda') if torch.cuda.is_available() else torch.device('cpu')

    # Load model
    model = torch.load(weights,
                       map_location=device)['model'].float()  # load to FP32
    # torch_utils.model_info(model)
    # model.fuse()
    model.to(device).eval()

    dataset = LoadImages(source, img_size=imgsz)

    # path2save = 'train2017/'
    # if not os.path.exists(yodatap + 'convertor/fold0/labels/'+path2save):
    #     os.makedirs(yodatap + 'convertor/fold0/labels/'+path2save)
    # if not os.path.exists(yodatap + 'convertor/fold0/images/{}'.format(path2save)):
    #     os.makedirs(yodatap + 'convertor/fold0/images/{}'.format(path2save))
    path2save = 'pseudo-yolo/'
    if not os.path.exists(yodatap_pseudo + 'labels/' + path2save):
        os.makedirs(yodatap + 'labels/' + path2save)
    if not os.path.exists(yodatap + 'images/{}'.format(path2save)):
        os.makedirs(yodatap + 'images/{}'.format(path2save))

    for name in imagenames:
        image_id = name.split('.')[0]
        im01 = cv2.imread('%s/%s.jpg' % (source, image_id))  # BGR
        if im01.shape[0] != 1024 or im01.shape[1] != 1024:
            continue
        assert im01 is not None, 'Image Not Found '
        # Padded resize
        im_w, im_h = im01.shape[:2]
        if is_TTA:
            enboxes = []
            enscores = []
            for i in range(4):
                im0 = TTAImage(im01, i)
                boxes, scores = detect1Image(im0, imgsz, model, device,
                                             conf_thres, iou_thres)
                for _ in range(3 - i):
                    boxes = rotBoxes90(boxes, im_w, im_h)

                enboxes.append(boxes)
                enscores.append(scores)

            boxes, scores, labels = run_wbf(enboxes,
                                            enscores,
                                            image_size=im_w,
                                            iou_thr=0.6,
                                            skip_box_thr=0.43)
            boxes = boxes.astype(np.int32).clip(min=0, max=im_w)
        else:
            boxes, scores = detect1Image(im01, imgsz, model, device,
                                         conf_thres, iou_thres)

        boxes[:, 2] = boxes[:, 2] - boxes[:, 0]
        boxes[:, 3] = boxes[:, 3] - boxes[:, 1]

        boxes = boxes[scores >= 0.05].astype(np.int32)
        scores = scores[scores >= float(0.05)]

        lineo = ''
        for box in boxes:
            x1, y1, w, h = box
            xc, yc, w, h = (x1 + w / 2) / 1024, (
                y1 + h / 2) / 1024, w / 1024, h / 1024
            lineo += '0 %f %f %f %f\n' % (xc, yc, w, h)
            # print(lineo, '\n')

        fileo = open(yodatap + 'labels/' + path2save + image_id + ".txt", 'w+')
        fileo.write(lineo)
        fileo.close()
        sh.copy(datapath + "/test/{}.jpg".format(image_id),
                yodatap + 'images/{}/{}.jpg'.format(path2save, image_id))
        print("done")


# makePseudolabel()

import cv2


def detect():
    source = datapath + "/test"
    weights = 'weights/best.pt'
    if not os.path.exists(weights):
        raise "weights path is wrong"
    imgsz = 1024
    conf_thres = 0.5
    iou_thres = 0.6
    is_TTA = True

    imagenames = os.listdir(source)

    device = torch.device(
        'cuda') if torch.cuda.is_available() else torch.device('cpu')

    # Load model
    model = torch.load(weights,
                       map_location=device)['model'].float()  # load to FP32
    model.to(device).eval()

    dataset = LoadImages(source, img_size=imgsz)

    results = []
    fig, ax = plt.subplots(5, 2, figsize=(30, 70))
    count = 0
    # img = torch.zeros((1, 3, imgsz, imgsz), device=device)  # init img
    #for path, img, im0s, _ in dataset:
    for name in imagenames:
        image_id = name.split('.')[0]
        im01 = cv2.imread('%s/%s.jpg' % (source, image_id))  # BGR
        assert im01 is not None, 'Image Not Found '
        # Padded resize
        im_w, im_h = im01.shape[:2]
        if is_TTA:
            enboxes = []
            enscores = []
            for i in range(4):
                im0 = TTAImage(im01, i)
                boxes, scores = detect1Image(im0, imgsz, model, device,
                                             conf_thres, iou_thres)
                for _ in range(3 - i):
                    boxes = rotBoxes90(boxes, im_w, im_h)

                if 1:  #i<3:
                    enboxes.append(boxes)
                    enscores.append(scores)
            boxes, scores = detect1Image(im01, imgsz, model, device,
                                         conf_thres, iou_thres)
            enboxes.append(boxes)
            enscores.append(scores)

            boxes, scores, labels = run_wbf(enboxes,
                                            enscores,
                                            image_size=im_w,
                                            iou_thr=0.6,
                                            skip_box_thr=0.5)
            boxes = boxes.astype(np.int32).clip(min=0, max=im_w)
        else:
            boxes, scores = detect1Image(im01, imgsz, model, device,
                                         conf_thres, iou_thres)

        boxes[:, 2] = boxes[:, 2] - boxes[:, 0]
        boxes[:, 3] = boxes[:, 3] - boxes[:, 1]

        boxes = boxes[scores >= 0.05].astype(np.int32)
        scores = scores[scores >= float(0.05)]
        if count < 10:
            #sample = image.permute(1,2,0).cpu().numpy()
            for box, score in zip(boxes, scores):
                cv2.rectangle(im0, (box[0], box[1]),
                              (box[2] + box[0], box[3] + box[1]), (220, 0, 0),
                              2)
                cv2.putText(im0, '%.2f' % (score), (box[0], box[1]),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2,
                            cv2.LINE_AA)
            ax[count % 5][count // 5].imshow(im0)
            count += 1

        result = {
            'image_id': image_id,
            'PredictionString': format_prediction_string(boxes, scores)
        }

        results.append(result)
    return results


def format_prediction_string(boxes, scores):
    pred_strings = []
    for j in zip(scores, boxes):
        pred_strings.append("{0:.4f} {1} {2} {3} {4}".format(
            j[0], j[1][0], j[1][1], j[1][2], j[1][3]))

    return " ".join(pred_strings)